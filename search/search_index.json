{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#grupo-404-name_not_found","title":"Grupo 404 - Name_Not_Found","text":""},{"location":"#integrantes","title":"Integrantes","text":"<ol> <li>Guilherme  Orlandi de Oliveira</li> <li>Luis Felipe Galina Degaspari</li> <li>Luiz Felipe Pimenta Berrettini</li> <li>Luiz Fernando Pazdziora Costa</li> </ol> <p>Estudantes do 4\u00b0 semestre de Ci\u00eancias de Dados e Neg\u00f3cios (CDN) na ESPM (Escola Superior de Propaganda e Marketing). </p> <p>Projetos de machine learning realizados em 2025.2, orientados e supervisionados pelo professor Humberto Sandmann.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Projeto 1 - Data 30/09/2025</li> <li> Projeto 2 - Data 05/12/2025</li> </ul>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"projeto/main/","title":"Projeto 1","text":""},{"location":"projeto/main/#modelo-de-machine-learning-arvore-de-decisoes-knn-e-k-means","title":"Modelo de Machine Learning - \u00c1rvore de Decis\u00f5es, KNN e K-Means","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Kaggle. Os dados usados podem ser baixados aqui, e foram adaptados de outra base de vinhos.</p>"},{"location":"projeto/main/#objetivo","title":"Objetivo","text":"<p>O dataset possui informa\u00e7\u00f5es diversas sobre resultados de an\u00e1lises qu\u00edmicas de vinhos produzidos na mesma regi\u00e3o da It\u00e1lia, mas derivados de tr\u00eas diferentes cultivares. A an\u00e1lise determinou as quantidade de 13 constituintes encontrados em cada um dos tr\u00eas tipos de vinho. O objetivo da an\u00e1lise \u00e9 clusterizar a base atrav\u00e9s do k-means e, com os modelos supervisionados, prever o tipo de vinho com base nos dados fornecidos.</p>"},{"location":"projeto/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"projeto/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>Primeiramente, para entender melhor a base de dados, vamos descobrir quantas linhas e colunas o dataset possui.</p> Sa\u00eddaC\u00f3digo <p>(178, 13)</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nprint(df.shape)\n</code></pre> <p>Como foi poss\u00edvel observar no c\u00f3digo acima, o dataset possui 178 linhas e 13 colunas, com cada linha possuindo os dados de um vinho.</p>"},{"location":"projeto/main/#colunas-do-dataset","title":"Colunas do Dataset","text":"<p>Em seguida, \u00e9 necess\u00e1rio descobrir a natureza dos dados. Isso ser\u00e1 feito rodando as linhas de c\u00f3digo abaixo:</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nprint(df.info())\n</code></pre> <p>As informa\u00e7\u00f5es obtidas foram as seguintes:</p> Coluna Tipo Descri\u00e7\u00e3o <code>Alcohol</code> Float Teor alco\u00f3lico do vinho <code>Malic_Acid</code> Float \u00c1cido m\u00e1lico <code>Ash</code> Float Cinzas <code>Ash_Alcanity</code> Float Alcalinidade das cinzas <code>Magnesium</code> Inteiro Magn\u00e9sio <code>Total_Phenols</code> Float Total de fen\u00f3is <code>Flavanoids</code> Float Flavan\u00f3ides <code>Nonflavanoid_Phenols</code> Float Fen\u00f3is n\u00e3o-flavan\u00f3ides <code>Proanthocyanins</code> Float Proantocianidinas <code>Color_Intensity</code> Float Intensidade da cor do vinho <code>Hue</code> Float Satura\u00e7\u00e3o do vinho <code>OD280</code> Float Rela\u00e7\u00e3o OD280/OD315 de vinhos dilu\u00eddos <code>Proline</code> Inteiro Prolina"},{"location":"projeto/main/#visualizacao-das-variaveis","title":"Visualiza\u00e7\u00e3o das vari\u00e1veis","text":"<p>Em seguida, \u00e9 essencial realizar gr\u00e1ficos para visualizar como cada uma das vari\u00e1veis se comportam, com o objetivo de entender melhor a base da dados. Todas vari\u00e1veis da base s\u00e3o quantitativas, sendo onze cont\u00ednuas e duas discretas.</p>"},{"location":"projeto/main/#variaveis-quantitativas-continuas","title":"Vari\u00e1veis Quantitativas Cont\u00ednuas","text":"<p>Para cada uma das vari\u00e1veis num\u00e9ricas cont\u00ednuas, ser\u00e1 feito um histograma com o objetivo de visualizar a frequ\u00eancia de valores.</p> AlcoholMalic_AcidAshAsh_AlcanityTotal_PhenolsFlavanoidsNonflavanoid_PhenolsProanthocyaninsColor_IntensityHueOD280 Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:46.267569 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Alcohol\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"red\")\nplt.title(\"Distribui\u00e7\u00e3o do Teor Alco\u00f3lico dos Vinhos - Histograma\")\nplt.xlabel(\"Teor Alco\u00f3lico\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:46.436025 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Malic_Acid\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"yellow\")\nplt.title(\"Distribui\u00e7\u00e3o de \u00c1cido M\u00e1lico dos Vinhos - Histograma\")\nplt.xlabel(\"\u00c1cido M\u00e1lico\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:46.589827 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Ash\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"green\")\nplt.title(\"Distribui\u00e7\u00e3o de Cinzas dos Vinhos - Histograma\")\nplt.xlabel(\"Cinzas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:46.773922 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Ash_Alcanity\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"blue\")\nplt.title(\"Distribui\u00e7\u00e3o da Alcalinidade das Cinzas dos Vinhos - Histograma\")\nplt.xlabel(\"Alcalinidade das Cinzas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:46.921957 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Total_Phenols\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"purple\")\nplt.title(\"Distribui\u00e7\u00e3o do Total de Fen\u00f3is dos Vinhos - Histograma\")\nplt.xlabel(\"Total de Fen\u00f3is\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.071106 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Flavanoids\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"orange\")\nplt.title(\"Distribui\u00e7\u00e3o de Flavan\u00f3ides dos Vinhos - Histograma\")\nplt.xlabel(\"Flavan\u00f3ides\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.224152 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Nonflavanoid_Phenols\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"lightblue\")\nplt.title(\"Distribui\u00e7\u00e3o de Fen\u00f3is n\u00e3o Flavan\u00f3ides dos Vinhos - Histograma\")\nplt.xlabel(\"Fen\u00f3is n\u00e3o Flavan\u00f3ides\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.371044 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Proanthocyanins\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"brown\")\nplt.title(\"Distribui\u00e7\u00e3o de Proantocianidinas dos Vinhos - Histograma\")\nplt.xlabel(\"Proantocianidinas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.522649 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Color_Intensity\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"grey\")\nplt.title(\"Distribui\u00e7\u00e3o de Intensidade da Cor dos Vinhos - Histograma\")\nplt.xlabel(\"Intensidade da Cor\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.675122 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Hue\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"lightgreen\")\nplt.title(\"Distribui\u00e7\u00e3o de Satura\u00e7\u00e3o dos Vinhos - Histograma\")\nplt.xlabel(\"Satura\u00e7\u00e3o\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.825720 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"OD280\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"pink\")\nplt.title(\"Distribui\u00e7\u00e3o do OD280 dos Vinhos - Histograma\")\nplt.xlabel(\"OD280\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre>"},{"location":"projeto/main/#variaveis-quantitativas-discretas","title":"Vari\u00e1veis Quantitativas Discretas","text":"<p>Para ambas vari\u00e1veis num\u00e9ricas discretas, tamb\u00e9m faremos histogramas.</p> MagnesiumProline Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:47.980522 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Magnesium\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"lightgreen\")\nplt.title(\"Distribui\u00e7\u00e3o de Magn\u00e9sio dos Vinhos - Histograma\")\nplt.xlabel(\"Magn\u00e9sio\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:48.123217 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Proline\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"skyblue\")\nplt.title(\"Distribui\u00e7\u00e3o de Prolina dos Vinhos - Histograma\")\nplt.xlabel(\"Prolina\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> <p>Atrav\u00e9s das an\u00e1lises, foi poss\u00edvel alcan\u00e7ar uma compreens\u00e3o mais aprofundada do funcionamento de cada uma das vari\u00e1veis no dataset, al\u00e9m de haver insights valiosos nesses gr\u00e1ficos.</p>"},{"location":"projeto/main/#etapa-2-pre-processamento","title":"Etapa 2 - Pr\u00e9-processamento","text":""},{"location":"projeto/main/#1-passo-identificacao-de-valores-nulos","title":"1\u00b0 Passo: Identifica\u00e7\u00e3o de valores nulos","text":"<p>Atrav\u00e9s da linha de c\u00f3digo abaixo, pode-se identificar que n\u00e3o h\u00e1 valores nulos na base. Portanto, pularemos o passo de tratamento de valores nulos.</p> <pre><code>print(df.isnull().sum())\n</code></pre>"},{"location":"projeto/main/#2-passo-remocao-de-colunas-desimportantes","title":"2\u00b0 Passo: Remo\u00e7\u00e3o de colunas desimportantes","text":"<p>N\u00e3o h\u00e1 colunas desimportantes para a an\u00e1lise no dataset. Um exemplo de coluna seria um identificador \u00fanico do vinho. Todas s\u00e3o vi\u00e1veis para o modelo de predi\u00e7\u00e3o.</p>"},{"location":"projeto/main/#3-passo-padronizacao-das-features-numericas","title":"3\u00b0 Passo: Padroniza\u00e7\u00e3o das features num\u00e9ricas","text":"<p>Por fim, \u00e9 necess\u00e1rio padronizar as features num\u00e9ricas da base. Ao inv\u00e9s da normaliza\u00e7\u00e3o, ser\u00e1 utilizada a t\u00e9cnica de padroniza\u00e7\u00e3o devido aos outliers nas features num\u00e9ricas. Para a padroniza\u00e7\u00e3o, foi utilizado o StandardScaler() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX = scaler.fit_transform(df)\n</code></pre>"},{"location":"projeto/main/#etapa-3-k-means","title":"Etapa 3 - K-Means","text":"<p>Nessa etapa, realizaremos um modelo K-Means para clusterizar a base e obter categorias que ser\u00e3o a vari\u00e1vel-alvo da previs\u00e3o dos modelos supervisionados. </p>"},{"location":"projeto/main/#elbow-method","title":"Elbow Method","text":"<p>Antes de treinar o modelo, \u00e9 necess\u00e1rio descobrir o n\u00famero de clusters que ser\u00e1 utilizado. Para isso, aplicaremos o Elbow Method.</p> ElbowC\u00f3digo <p></p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\nwcss = []\nk_range = range(1, 11)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\nplt.figure(figsize=(10, 6))\nplt.plot(k_range, wcss, \"bo-\", markersize=8, linewidth=2)\nplt.xlabel(\"N\u00famero de Clusters (K)\")\nplt.ylabel(\"WCSS (Within-Cluster Sum of Square)\")\nplt.title(\"Elbow Method - Determinando o K ideal\")\nplt.grid(True, alpha=0.3)\nplt.xticks(k_range)\n\nplt.axvline(x=3, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Poss\u00edvel cotovelo K=3\")\n\nplt.legend()\n# plt.savefig(\"docs/projeto/images/elbow.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre> <p>Podemos observar que o cotovelo est\u00e1 em \\(k = 3\\), logo, esse ser\u00e1 o n\u00famero de clusters utilizado para o K-Means.</p>"},{"location":"projeto/main/#treinamento-do-k-means","title":"Treinamento do K-Means","text":"<p>Para a forma\u00e7\u00e3o dos clusters do K-Means, foi utilizado a t\u00e9cnica do PCA (Principal Component Analysis). </p> K-Means PCAC\u00f3digo <p></p> Silhouette Score: 0.2849 <p></p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(X)\n\nsilhouette_avg = silhouette_score(X, cluster_labels)\nprint(f\"Silhouette Score: {silhouette_avg:.4f}\")\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap=\"viridis\", alpha=0.7)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker=\"*\", s=300, c=\"red\", label=\"Centroids\")\n\nplt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%} var.)\")\nplt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%} var.)\")\nplt.title(\"Clusters de Vinhos - K-means (K=3)\")\nplt.legend()\nplt.colorbar(scatter, label=\"Cluster\")\n\n# plt.savefig(\"docs/projeto/images/k-means.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre>"},{"location":"projeto/main/#etapa-4-avaliacao-do-k-means","title":"Etapa 4 - Avalia\u00e7\u00e3o do K-Means","text":""},{"location":"projeto/main/#silhouette-score","title":"Silhouette Score","text":"<p>O modelo alcan\u00e7ou um Silhouette Score de 0.2849, indicando uma estrutura de clusters potencialmente artificial. Na escala de -1 a +1, este valor se enquadra na categoria Fraca, por\u00e9m ainda acima do limiar de 0.25 que indicaria aus\u00eancia de clusters naturais.</p>"},{"location":"projeto/main/#variancia-explicada","title":"Vari\u00e2ncia Explicada","text":"<p>O PCA aplicado para visualiza\u00e7\u00e3o explica 55.41% da vari\u00e2ncia total dos dados. Embora seja uma representa\u00e7\u00e3o simplificada, \u00e9 suficiente para identificar padr\u00f5es gerais, por\u00e9m pode n\u00e3o capturar estruturas mais complexas n\u00e3o-lineares.</p>"},{"location":"projeto/main/#conclusao-da-avaliacao","title":"Conclus\u00e3o da avalia\u00e7\u00e3o","text":"<p>O silhouette score ficou baixo, por isso, vamos tentar outra t\u00e9cnica que n\u00e3o o PCA. Vamos explorar o t-SNE (t-Distributed Stochastic Neighbor Embedding), uma t\u00e9cnica n\u00e3o-linear que pode revelar melhor estruturas locais e agrupamentos n\u00e3o capturados pelo PCA.</p>"},{"location":"projeto/main/#re-treinamento-do-k-means","title":"Re-treinamento do k-means","text":"K-Means t-SNEC\u00f3digo Silhouette Score: 0.5928 <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import silhouette_score\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\ntsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\nX_tsne = tsne.fit_transform(X)\n\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(X)\n\nsilhouette_avg = silhouette_score(X_tsne, cluster_labels)\nprint(f\"Silhouette Score: {silhouette_avg:.4f}\")\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cluster_labels, cmap=\"viridis\", alpha=0.7)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n           marker=\"*\", s=300, c=\"red\", label=\"Centroids\")\n\nplt.xlabel(\"t-SNE Component 1\")\nplt.ylabel(\"t-SNE Component 2\")\nplt.title(f\"Clusters de Vinhos - t-SNE + K-means (K=3)\\nSilhouette: {silhouette_avg:.4f}\")\nplt.legend()\nplt.colorbar(scatter, label=\"Cluster\")\n\n# plt.savefig(\"docs/projeto/images/k-means-tsne.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre> <p>Foi poss\u00edvel observar uma melhora significativa no silhouette score, de 0.2849 com PCA para 0.5928 com t-SNE, indicando uma estrutura de clusters muito mais definida.</p> <p>Os centr\u00f3ides na visualiza\u00e7\u00e3o t-SNE podem parecer \"estranhos\" porque esta t\u00e9cnica prioriza a preserva\u00e7\u00e3o de estruturas locais em detrimento de rela\u00e7\u00f5es globais e densidades. O t-SNE distorce intencionalmente o espa\u00e7o para destacar agrupamentos pr\u00f3ximos, o que explica a posi\u00e7\u00e3o n\u00e3o convencional dos centr\u00f3ides na visualiza\u00e7\u00e3o.</p> <p>Em resumo, o trade-off vale a pena: mesmo com a perda de informa\u00e7\u00f5es sobre densidades e estruturas globais, a qualidade da clusteriza\u00e7\u00e3o melhorou drasticamente, revelando padr\u00f5es que n\u00e3o eram aparentes com PCA.</p>"},{"location":"projeto/main/#criando-a-coluna-da-variavel-alvo","title":"Criando a coluna da vari\u00e1vel-alvo","text":"<p>Agora, vamos criar a coluna que conter\u00e1 a vari\u00e1vel categ\u00f3rica <code>Wine_Type</code>, criada a partir da clusteriza\u00e7\u00e3o do K-Means com t-SNE. Essa coluna ser\u00e1 a vari\u00e1vel-alvo das an\u00e1lises preditivas feitas pelos modelos supervisionados adiante.</p> Sa\u00eddaC\u00f3digo <p>Distribui\u00e7\u00e3o dos clusters - Wine Type 1: 65 Wine Type 2: 51 Wine Type 3: 62</p> <pre><code>import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\ntsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\nX_tsne = tsne.fit_transform(X)\n\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(X)\n\ndf[\"cluster\"] = cluster_labels\ndf[\"Wine_Type\"] = [f\"Wine Type {label + 1}\" for label in cluster_labels]\n\nprint(\"Distribui\u00e7\u00e3o dos clusters -&lt;br&gt;\")\nfor i in range(1, 4):\n    count = len(df[df['Wine_Type'] == f'Wine Type {i}'])\n    print(f\"Wine Type {i}: {count}&lt;br&gt;\")\n\n# Salvar para csv\n# df.to_csv(\"wine-final.csv\", index=False)\n</code></pre> <p>Com isso, podemos partir para as pr\u00f3ximas etapas.</p>"},{"location":"projeto/main/#etapa-5-divisao-de-dados","title":"Etapa 5 - Divis\u00e3o de dados","text":"<p>Em seguida, vamos realizar a divis\u00e3o dos dados em conjuntos de treino e teste.</p> <ul> <li> <p>Conjunto de Treino: Utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: Utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, foi utilizada a fun\u00e7\u00e3o train_test_split() do <code>scikit-learn</code>. Os par\u00e2metros utilizados s\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> <li> <p>stratify=y: Esse atributo definido como y \u00e9 essencial devido \u00e0 natureza da coluna <code>Wine_Type</code>. Com essa defini\u00e7\u00e3o, ser\u00e1 mantida a mesma propor\u00e7\u00e3o das categorias em ambos os conjuntos, reduzindo o vi\u00e9s.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 142 amostras</p> <p>Teste: 36 amostras</p> <p>Propor\u00e7\u00e3o: 79.8% treino, 20.2% teste</p> <p>Distribui\u00e7\u00e3o das classes - </p> <p>Treino:</p> Wine_Type count Wine Type 1 52 Wine Type 3 49 Wine Type 2 41 <p>Teste:</p> Wine_Type count Wine Type 3 13 Wine Type 1 13 Wine Type 2 10 <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(\"Wine_Type\", axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Treino: {X_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {X_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {X_train.shape[0]/X.shape[0]*100:.1f}% treino, {X_test.shape[0]/X.shape[0]*100:.1f}% teste\\n\")\n\nprint(\"Distribui\u00e7\u00e3o das classes - \\n\")\nprint(\"Treino:\\n\")\nprint(y_train.value_counts().to_markdown(), \"\\n\")\nprint(\"Teste:\\n\")\nprint(y_test.value_counts().to_markdown(), \"\\n\")\n</code></pre> <p>Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting.</p>"},{"location":"projeto/main/#etapa-6-treinamento-do-modelo-decision-tree","title":"Etapa 6 - Treinamento do modelo Decision Tree","text":"<p>Agora, vamos treinar um modelo de \u00e1rvore de decis\u00f5es (Decision Tree) para prever a vari\u00e1vel alvo <code>Wine_Type</code> para os dados do conjunto teste. Nosso objetivo aqui \u00e9 treinar e avaliar o modelo, para depois compar\u00e1-lo ao KNN e decidir o melhor para este caso.</p> Decision TreeC\u00f3digo <p></p> <p></p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\n\nplt.figure(figsize=(12,9))\ntree.plot_tree(\n    classifier,\n    feature_names=pd.DataFrame(X).columns,\n    class_names=classifier.classes_,\n    filled=True,\n    rounded=True,\n    max_depth=3,\n    fontsize=10\n)\nplt.title(\"\u00c1rvore de Decis\u00e3o - Faixas de \u00c1lcool (Vinhos)\")\n\n# plt.savefig(\"docs/projeto/images/d-tree.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre>"},{"location":"projeto/main/#etapa-7-avaliacao-do-modelo-decision-tree","title":"Etapa 7 - Avalia\u00e7\u00e3o do modelo Decision Tree","text":"<p>Agora, vamos realizar a avalia\u00e7\u00e3o do modelo treinado. Primeiramente, vamos ver a acur\u00e1cia do modelo e a import\u00e2ncia de cada uma das features utilizadas para a predi\u00e7\u00e3o.</p> Sa\u00eddaC\u00f3digo <p>Acur\u00e1cia do Modelo: 0.8889 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 12 Proline 0.427374 11 OD280 0.359550 6 Flavanoids 0.113809 9 Color_Intensity 0.076206 1 Malic_Acid 0.018196 0 Alcohol 0.004865 4 Magnesium 0.000000 2 Ash 0.000000 3 Ash_Alcanity 0.000000 8 Proanthocyanins 0.000000 7 Nonflavanoid_Phenols 0.000000 5 Total_Phenols 0.000000 10 Hue 0.000000 </p> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Acur\u00e1cia do Modelo: {accuracy:.4f}\")\n\nfeature_names = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1).columns\n\nfeature_importance = pd.DataFrame({\n    \"Feature\": feature_names,\n    \"Import\u00e2ncia\": classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by=\"Import\u00e2ncia\", ascending=False).to_html() + \"&lt;br&gt;\")\n</code></pre>"},{"location":"projeto/main/#acuracia","title":"Acur\u00e1cia","text":"<p>O modelo atingiu uma boa acur\u00e1cia, de 88,89%, bem pr\u00f3ximo do ideal de 95%. Isso significa que, em 88,89% das previs\u00f5es feitas, o tipo de vinho predito est\u00e1 correto.</p>"},{"location":"projeto/main/#importancia-das-features","title":"Import\u00e2ncia das features","text":"<ul> <li> <p>Na tabela de import\u00e2ncia das features, podemos notar que a vari\u00e1vel mais importante para a previs\u00e3o \u00e9 a <code>Proline</code>, com 42,74% de import\u00e2ncia na previs\u00e3o. </p> </li> <li> <p>Diversas vari\u00e1veis tiveram uma import\u00e2ncia nula, sendo elas: <code>Magnesium</code>, <code>Ash</code>, <code>Ash_Alcanity</code>, <code>Proanthocyanins</code>, <code>Nonflavanoid_Phenols</code>, <code>Total_Phenols</code> e <code>Hue</code></p> </li> <li> <p>As vari\u00e1veis <code>Malic_Acid</code> e <code>Alcohol</code> tiveram uma import\u00e2ncia quase irrelevante na predi\u00e7\u00e3o, de 1,82% e 0,49% respectivamente.</p> </li> </ul>"},{"location":"projeto/main/#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":"<p>Agora, vamos visualizar a matriz de confus\u00e3o do modelo.</p> Sa\u00eddaC\u00f3digo <p>Matriz de confus\u00e3o</p> <p></p> <p>M\u00e9tricas de qualidade</p> precision recall f1-score support Wine Type 1 0.8 0.92 0.86 13 Wine Type 2 0.9 0.9 0.9 10 Wine Type 3 1 0.85 0.92 13 accuracy 0.89 0.89 0.89 0.89 macro avg 0.9 0.89 0.89 36 weighted avg 0.9 0.89 0.89 36 <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn import tree\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classifier.classes_)\ndisp.plot(cmap=\"Blues\")\nplt.title(\"Matriz de Confus\u00e3o - Wine\")\n# plt.savefig(\"docs/projeto/images/cm-d-tree.svg\", format=\"svg\", transparent=True)\nplt.close()\n\nreport_dict = classification_report(y_test, y_pred, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\nprint(report_df.round(2).to_markdown())\n</code></pre>"},{"location":"projeto/main/#avaliacao-das-metricas","title":"Avalia\u00e7\u00e3o das m\u00e9tricas","text":"<p>Pontos Positivos</p> <ul> <li> <p>Boa acur\u00e1cia geral: 89% - modelo consegue classificar corretamente a maioria das inst\u00e2ncias</p> </li> <li> <p>Excelente precis\u00e3o para Wine Type 3: 100% - quando o modelo classifica como tipo 3, est\u00e1 sempre correto</p> </li> <li> <p>Recall alto para Wine Type 1: 92% - consegue identificar quase todos os vinhos do tipo 1</p> </li> <li> <p>Balanceamento razo\u00e1vel: M\u00e9tricas similares entre as classes</p> </li> </ul> <p>Pontos de Melhoria</p> <p>Problema com Wine Type 3:</p> <ul> <li>Recall de 85% - o modelo falha em identificar 15% dos vinhos do tipo 3</li> </ul> <p>Isso significa que 15% dos vinhos tipo 3 est\u00e3o sendo classificados erroneamente como outros tipos</p> <p>Precis\u00e3o do Wine Type 1:</p> <ul> <li>80% - quando o modelo diz \"\u00e9 tipo 1\", em 20% dos casos est\u00e1 errado</li> </ul>"},{"location":"projeto/main/#etapa-8-treinamento-do-modelo-knn","title":"Etapa 8 - Treinamento do Modelo KNN","text":"<p>Agora, vamos treinar um modelo de KNN para prever a vari\u00e1vel alvo <code>Wine_Type</code> para os dados do conjunto teste. Nosso objetivo aqui \u00e9 treinar e avaliar o modelo, para depois compar\u00e1-lo ao modelo de \u00e1rvore de decis\u00f5es e apontar o modelo superior para este caso.</p> KNNC\u00f3digo <p></p> Acur\u00e1cia: 0.9722  <p></p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}&lt;br&gt;\")\n\n# Visualiza\u00e7\u00e3o do KNN \n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"Variance explained by each component:\", pca.explained_variance_ratio_)\n\nX_train_pca, X_test_pca, _, _ = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\nknn_pca = KNeighborsClassifier(n_neighbors=3)\nknn_pca.fit(X_train_pca, y_train)\n\nh = .05\nx_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\ny_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\nnp.arange(y_min, y_max, h))\n\nZ = knn_pca.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure(figsize=(10, 7))\nplt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette=\"coolwarm\", edgecolor=\"k\", s=60)\nplt.title(\"KNN com PCA do Modelo 1)\")\nplt.xlabel(\"Componente Principal 1\")\nplt.ylabel(\"Componente Principal 2\")\nplt.legend(title=\"Booking status\")\n\n# plt.savefig(\"docs/projeto/images/knn.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre>"},{"location":"projeto/main/#etapa-9-avaliacao-do-modelo-knn","title":"Etapa 9 - Avalia\u00e7\u00e3o do modelo KNN","text":"<p>Agora, vamos realizar a avalia\u00e7\u00e3o do modelo KNN.</p>"},{"location":"projeto/main/#acuracia_1","title":"Acur\u00e1cia","text":"<p>O modelo alcan\u00e7ou uma acur\u00e1cia de 97,22%, que \u00e9 excelente, contudo indica poss\u00edvel overfitting no modelo. Para testar essa hip\u00f3tese, vamos fazer um teste de acur\u00e1cia nos conjuntos de treino e teste separadamente com KNN e uma valida\u00e7\u00e3o cruzada.</p>"},{"location":"projeto/main/#acuracias-dos-conjuntos-e-validacao-cruzada","title":"Acur\u00e1cias dos conjuntos e valida\u00e7\u00e3o cruzada","text":"Testes overfittingC\u00f3digo <p>Acur\u00e1cias dos conjuntos -</p> <p>Acur\u00e1cia no Treino: 0.9718 </p> <p>Acur\u00e1cia no Teste: 0.9722</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.88888889 0.97222222 0.97222222 1.         0.94285714]</p> <p>M\u00e9dia: 0.9552 (+/- 0.0756)</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nX_train_pca, X_test_pca, _, _ = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\nknn_pca = KNeighborsClassifier(n_neighbors=3)\nknn_pca.fit(X_train_pca, y_train)\n\ntrain_accuracy = knn.score(X_train, y_train)\ntest_accuracy = knn.score(X_test, y_test)\nprint(f\"\\n&lt;b&gt;Acur\u00e1cias dos conjuntos -&lt;/b&gt;\\n\")\nprint(f\"Acur\u00e1cia no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"Acur\u00e1cia no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(knn, X, y_encoded, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>Com esses resultados, podemos concluir que h\u00e1 muita chance desse n\u00e3o ser um caso de overfitting. Isso porque as acur\u00e1cias dos conjuntos s\u00e3o consistentes. Al\u00e9m disso, a valida\u00e7\u00e3o cruzada nos demonstrou uma alta m\u00e9dia, de 95,52%, um desvio padr\u00e3o baixo e uma varia\u00e7\u00e3o dos scores entre 88,9% \u00e0 100%, uma varia\u00e7\u00e3o normal.</p>"},{"location":"projeto/main/#matriz-de-confusao_1","title":"Matriz de Confus\u00e3o","text":"Matriz de Confus\u00e3oC\u00f3digo <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\n\ncm = confusion_matrix(y_test, predictions)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\nplt.xlabel(\"Predito\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o - KNN\")\n\n# plt.savefig(\"docs/projeto/images/cm-knn.svg\", format=\"svg\", transparent=True)\nplt.close()\n\nreport_dict = classification_report(y_test, predictions, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\nprint(report_df.round(2).to_markdown())\n</code></pre> <p>O modelo atingiu uma performance excepcional, com acur\u00e1cia geral de 97%, classe 1 perfeitamente prevista pelo modelo com Precis\u00e3o, Recall e F1-Score de 1.00 e alta consist\u00eancia geral, j\u00e1 que todas classes possuem F1-Score acima de 0.96.</p>"},{"location":"projeto/main/#metricas-de-qualidade","title":"M\u00e9tricas de qualidade","text":"precision recall f1-score support 0 1 0.92 0.96 13 1 1 1 1 9 2 0.93 1 0.97 14 accuracy 0.97 0.97 0.97 0.97 macro avg 0.98 0.97 0.98 36 weighted avg 0.97 0.97 0.97 36"},{"location":"projeto/main/#etapa-10-relatorio-final","title":"Etapa 10 - Relat\u00f3rio Final","text":"<p>Ap\u00f3s extensa an\u00e1lise comparativa dos modelos desenvolvidos para a classifica\u00e7\u00e3o de vinhos, o algoritmo K-Nearest Neighbors (KNN) emergiu como a escolha ideal para este problema preditivo, demonstrando performance excepcionalmente superior em todas as m\u00e9tricas de avalia\u00e7\u00e3o. </p> <p>A estrat\u00e9gia de clusteriza\u00e7\u00e3o com K-Means utilizando visualiza\u00e7\u00e3o t-SNE provou-se notavelmente superior \u00e0 abordagem com PCA, oferecendo:</p> <ul> <li> <p>Separa\u00e7\u00e3o mais n\u00edtida entre os clusters de vinhos</p> </li> <li> <p>Preserva\u00e7\u00e3o superior das estruturas locais dos dados</p> </li> <li> <p>Visualiza\u00e7\u00e3o mais intuitiva das rela\u00e7\u00f5es entre as variedades</p> </li> <li> <p>Agrupamentos mais coesos e semanticamente significativos</p> </li> </ul> <p>O t-SNE demonstrou boa capacidade em revelar a estrutura subjacente do dataset, permitindo identificar grupos naturais de vinhos que se alinham perfeitamente com suas caracter\u00edsticas intr\u00ednsecas e qualidade.</p> <p>Embora o K-Means com t-SNE tenha demonstrado resultados promissores, o Silhouette Score de 0.5928 indica espa\u00e7o para otimiza\u00e7\u00e3o, sugerindo que a separa\u00e7\u00e3o entre clusters pode ser aprimorada atrav\u00e9s de outras t\u00e9cnicas como DBSCAN, al\u00e9m do refinamento do pr\u00e9-processamento dos dados e experimenta\u00e7\u00e3o com diferentes redu\u00e7\u00f5es de dimensionalidade.</p>"},{"location":"projeto2/main/","title":"Projeto Extra","text":""},{"location":"projeto2/main/#modelo-de-machine-learning-k-means-random-forest-e-svm","title":"Modelo de Machine Learning - K-means, Random Forest e SVM","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Kaggle. Os dados usados podem ser baixados aqui, e foram adaptados de outra base de vinhos. Esse projeto utiliza a mesma base do projeto anterior. Portanto, at\u00e9 a Etapa 5, todos os passos s\u00e3o os mesmos.</p>"},{"location":"projeto2/main/#objetivo","title":"Objetivo","text":"<p>O dataset possui informa\u00e7\u00f5es diversas sobre resultados de an\u00e1lises qu\u00edmicas de vinhos produzidos na mesma regi\u00e3o da It\u00e1lia, mas derivados de tr\u00eas diferentes cultivares. A an\u00e1lise determinou as quantidade de 13 constituintes encontrados em cada um dos tr\u00eas tipos de vinho. O objetivo da an\u00e1lise \u00e9 clusterizar a base atrav\u00e9s do k-means e, com os modelos supervisionados, prever o tipo de vinho com base nos dados fornecidos.</p>"},{"location":"projeto2/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"projeto2/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>Primeiramente, para entender melhor a base de dados, vamos descobrir quantas linhas e colunas o dataset possui.</p> Sa\u00eddaC\u00f3digo <p>(178, 13)</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nprint(df.shape)\n</code></pre> <p>Como foi poss\u00edvel observar no c\u00f3digo acima, o dataset possui 178 linhas e 13 colunas, com cada linha possuindo os dados de um vinho.</p>"},{"location":"projeto2/main/#colunas-do-dataset","title":"Colunas do Dataset","text":"<p>Em seguida, \u00e9 necess\u00e1rio descobrir a natureza dos dados. Isso ser\u00e1 feito rodando as linhas de c\u00f3digo abaixo:</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nprint(df.info())\n</code></pre> <p>As informa\u00e7\u00f5es obtidas foram as seguintes:</p> Coluna Tipo Descri\u00e7\u00e3o <code>Alcohol</code> Float Teor alco\u00f3lico do vinho <code>Malic_Acid</code> Float \u00c1cido m\u00e1lico <code>Ash</code> Float Cinzas <code>Ash_Alcanity</code> Float Alcalinidade das cinzas <code>Magnesium</code> Inteiro Magn\u00e9sio <code>Total_Phenols</code> Float Total de fen\u00f3is <code>Flavanoids</code> Float Flavan\u00f3ides <code>Nonflavanoid_Phenols</code> Float Fen\u00f3is n\u00e3o-flavan\u00f3ides <code>Proanthocyanins</code> Float Proantocianidinas <code>Color_Intensity</code> Float Intensidade da cor do vinho <code>Hue</code> Float Satura\u00e7\u00e3o do vinho <code>OD280</code> Float Rela\u00e7\u00e3o OD280/OD315 de vinhos dilu\u00eddos <code>Proline</code> Inteiro Prolina"},{"location":"projeto2/main/#visualizacao-das-variaveis","title":"Visualiza\u00e7\u00e3o das vari\u00e1veis","text":"<p>Em seguida, \u00e9 essencial realizar gr\u00e1ficos para visualizar como cada uma das vari\u00e1veis se comportam, com o objetivo de entender melhor a base da dados. Todas vari\u00e1veis da base s\u00e3o quantitativas, sendo onze cont\u00ednuas e duas discretas.</p>"},{"location":"projeto2/main/#variaveis-quantitativas-continuas","title":"Vari\u00e1veis Quantitativas Cont\u00ednuas","text":"<p>Para cada uma das vari\u00e1veis num\u00e9ricas cont\u00ednuas, ser\u00e1 feito um histograma com o objetivo de visualizar a frequ\u00eancia de valores.</p> AlcoholMalic_AcidAshAsh_AlcanityTotal_PhenolsFlavanoidsNonflavanoid_PhenolsProanthocyaninsColor_IntensityHueOD280 Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:51.538019 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Alcohol\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"red\")\nplt.title(\"Distribui\u00e7\u00e3o do Teor Alco\u00f3lico dos Vinhos - Histograma\")\nplt.xlabel(\"Teor Alco\u00f3lico\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:51.699964 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Malic_Acid\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"yellow\")\nplt.title(\"Distribui\u00e7\u00e3o de \u00c1cido M\u00e1lico dos Vinhos - Histograma\")\nplt.xlabel(\"\u00c1cido M\u00e1lico\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:51.852202 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Ash\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"green\")\nplt.title(\"Distribui\u00e7\u00e3o de Cinzas dos Vinhos - Histograma\")\nplt.xlabel(\"Cinzas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.005630 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Ash_Alcanity\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"blue\")\nplt.title(\"Distribui\u00e7\u00e3o da Alcalinidade das Cinzas dos Vinhos - Histograma\")\nplt.xlabel(\"Alcalinidade das Cinzas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.154124 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Total_Phenols\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"purple\")\nplt.title(\"Distribui\u00e7\u00e3o do Total de Fen\u00f3is dos Vinhos - Histograma\")\nplt.xlabel(\"Total de Fen\u00f3is\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.303972 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Flavanoids\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"orange\")\nplt.title(\"Distribui\u00e7\u00e3o de Flavan\u00f3ides dos Vinhos - Histograma\")\nplt.xlabel(\"Flavan\u00f3ides\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.459378 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Nonflavanoid_Phenols\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"lightblue\")\nplt.title(\"Distribui\u00e7\u00e3o de Fen\u00f3is n\u00e3o Flavan\u00f3ides dos Vinhos - Histograma\")\nplt.xlabel(\"Fen\u00f3is n\u00e3o Flavan\u00f3ides\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.608060 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Proanthocyanins\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"brown\")\nplt.title(\"Distribui\u00e7\u00e3o de Proantocianidinas dos Vinhos - Histograma\")\nplt.xlabel(\"Proantocianidinas\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.759143 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Color_Intensity\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"grey\")\nplt.title(\"Distribui\u00e7\u00e3o de Intensidade da Cor dos Vinhos - Histograma\")\nplt.xlabel(\"Intensidade da Cor\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:52.909094 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Hue\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"lightgreen\")\nplt.title(\"Distribui\u00e7\u00e3o de Satura\u00e7\u00e3o dos Vinhos - Histograma\")\nplt.xlabel(\"Satura\u00e7\u00e3o\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:53.058696 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"OD280\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"pink\")\nplt.title(\"Distribui\u00e7\u00e3o do OD280 dos Vinhos - Histograma\")\nplt.xlabel(\"OD280\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre>"},{"location":"projeto2/main/#variaveis-quantitativas-discretas","title":"Vari\u00e1veis Quantitativas Discretas","text":"<p>Para ambas vari\u00e1veis num\u00e9ricas discretas, tamb\u00e9m faremos histogramas.</p> MagnesiumProline Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:53.278065 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Magnesium\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"lightgreen\")\nplt.title(\"Distribui\u00e7\u00e3o de Magn\u00e9sio dos Vinhos - Histograma\")\nplt.xlabel(\"Magn\u00e9sio\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:53.419301 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(df[\"Proline\"], bins=30, edgecolor=\"black\", alpha=0.7, color=\"skyblue\")\nplt.title(\"Distribui\u00e7\u00e3o de Prolina dos Vinhos - Histograma\")\nplt.xlabel(\"Prolina\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.grid(axis=\"y\", alpha=0.3)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> <p>Atrav\u00e9s das an\u00e1lises, foi poss\u00edvel alcan\u00e7ar uma compreens\u00e3o mais aprofundada do funcionamento de cada uma das vari\u00e1veis no dataset, al\u00e9m de haver insights valiosos nesses gr\u00e1ficos.</p>"},{"location":"projeto2/main/#etapa-2-pre-processamento","title":"Etapa 2 - Pr\u00e9-processamento","text":""},{"location":"projeto2/main/#1-passo-identificacao-de-valores-nulos","title":"1\u00b0 Passo: Identifica\u00e7\u00e3o de valores nulos","text":"<p>Atrav\u00e9s da linha de c\u00f3digo abaixo, pode-se identificar que n\u00e3o h\u00e1 valores nulos na base. Portanto, pularemos o passo de tratamento de valores nulos.</p> <pre><code>print(df.isnull().sum())\n</code></pre>"},{"location":"projeto2/main/#2-passo-remocao-de-colunas-desimportantes","title":"2\u00b0 Passo: Remo\u00e7\u00e3o de colunas desimportantes","text":"<p>N\u00e3o h\u00e1 colunas desimportantes para a an\u00e1lise no dataset. Um exemplo de coluna seria um identificador \u00fanico do vinho. Todas s\u00e3o vi\u00e1veis para o modelo de predi\u00e7\u00e3o.</p>"},{"location":"projeto2/main/#3-passo-padronizacao-das-features-numericas","title":"3\u00b0 Passo: Padroniza\u00e7\u00e3o das features num\u00e9ricas","text":"<p>Por fim, \u00e9 necess\u00e1rio padronizar as features num\u00e9ricas da base. Ao inv\u00e9s da normaliza\u00e7\u00e3o, ser\u00e1 utilizada a t\u00e9cnica de padroniza\u00e7\u00e3o devido aos outliers nas features num\u00e9ricas. Para a padroniza\u00e7\u00e3o, foi utilkizado o StandardScaler() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX = scaler.fit_transform(df)\n</code></pre>"},{"location":"projeto2/main/#etapa-3-k-means","title":"Etapa 3 - K-Means","text":"<p>Nessa etapa, realizaremos um modelo K-Means para clusterizar a base e obter categorias que ser\u00e3o a vari\u00e1vel-alvo da previs\u00e3o dos modelos supervisionados. </p>"},{"location":"projeto2/main/#elbow-method","title":"Elbow Method","text":"<p>Antes de treinar o modelo, \u00e9 necess\u00e1rio descobrir o n\u00famero de clusters que ser\u00e1 utilizado. Para isso, aplicaremos o Elbow Method.</p> ElbowC\u00f3digo <p></p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\nwcss = []\nk_range = range(1, 11)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\nplt.figure(figsize=(10, 6))\nplt.plot(k_range, wcss, \"bo-\", markersize=8, linewidth=2)\nplt.xlabel(\"N\u00famero de Clusters (K)\")\nplt.ylabel(\"WCSS (Within-Cluster Sum of Square)\")\nplt.title(\"Elbow Method - Determinando o K ideal\")\nplt.grid(True, alpha=0.3)\nplt.xticks(k_range)\n\nplt.axvline(x=3, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Poss\u00edvel cotovelo K=3\")\n\nplt.legend()\n# plt.savefig(\"docs/projeto/images/elbow.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre> <p>Podemos observar que o cotovelo est\u00e1 em \\(k = 3\\), logo, esse ser\u00e1 o n\u00famero de clusters utilizado para o K-Means.</p>"},{"location":"projeto2/main/#treinamento-do-k-means","title":"Treinamento do K-Means","text":"<p>Para a forma\u00e7\u00e3o dos clusters do K-Means, foi utilizado a t\u00e9cnica do PCA (Principal Component Analysis). </p> K-Means PCAC\u00f3digo <p></p> Silhouette Score: 0.2849 <p></p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(X)\n\nsilhouette_avg = silhouette_score(X, cluster_labels)\nprint(f\"Silhouette Score: {silhouette_avg:.4f}\")\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap=\"viridis\", alpha=0.7)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker=\"*\", s=300, c=\"red\", label=\"Centroids\")\n\nplt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%} var.)\")\nplt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%} var.)\")\nplt.title(\"Clusters de Vinhos - K-means (K=3)\")\nplt.legend()\nplt.colorbar(scatter, label=\"Cluster\")\n\n# plt.savefig(\"docs/projeto/images/k-means.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre>"},{"location":"projeto2/main/#etapa-4-avaliacao-do-k-means","title":"Etapa 4 - Avalia\u00e7\u00e3o do K-Means","text":""},{"location":"projeto2/main/#silhouette-score","title":"Silhouette Score","text":"<p>O modelo alcan\u00e7ou um Silhouette Score de 0.2849, indicando uma estrutura de clusters potencialmente artificial. Na escala de -1 a +1, este valor se enquadra na categoria Fraca, por\u00e9m ainda acima do limiar de 0.25 que indicaria aus\u00eancia de clusters naturais.</p>"},{"location":"projeto2/main/#variancia-explicada","title":"Vari\u00e2ncia Explicada","text":"<p>O PCA aplicado para visualiza\u00e7\u00e3o explica 55.41% da vari\u00e2ncia total dos dados. Embora seja uma representa\u00e7\u00e3o simplificada, \u00e9 suficiente para identificar padr\u00f5es gerais, por\u00e9m pode n\u00e3o capturar estruturas mais complexas n\u00e3o-lineares.</p>"},{"location":"projeto2/main/#conclusao-da-avaliacao","title":"Conclus\u00e3o da avalia\u00e7\u00e3o","text":"<p>O silhouette score ficou baixo, por isso, vamos tentar outra t\u00e9cnica que n\u00e3o o PCA. Vamos explorar o t-SNE (t-Distributed Stochastic Neighbor Embedding), uma t\u00e9cnica n\u00e3o-linear que pode revelar melhor estruturas locais e agrupamentos n\u00e3o capturados pelo PCA.</p>"},{"location":"projeto2/main/#re-treinamento-do-k-means","title":"Re-treinamento do k-means","text":"K-Means t-SNEC\u00f3digo Silhouette Score: 0.5928 <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import silhouette_score\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\ntsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\nX_tsne = tsne.fit_transform(X)\n\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(X)\n\nsilhouette_avg = silhouette_score(X_tsne, cluster_labels)\nprint(f\"Silhouette Score: {silhouette_avg:.4f}\")\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cluster_labels, cmap=\"viridis\", alpha=0.7)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n           marker=\"*\", s=300, c=\"red\", label=\"Centroids\")\n\nplt.xlabel(\"t-SNE Component 1\")\nplt.ylabel(\"t-SNE Component 2\")\nplt.title(f\"Clusters de Vinhos - t-SNE + K-means (K=3)\\nSilhouette: {silhouette_avg:.4f}\")\nplt.legend()\nplt.colorbar(scatter, label=\"Cluster\")\n\n# plt.savefig(\"docs/projeto/images/k-means-tsne.svg\", format=\"svg\", transparent=True)\nplt.close()\n</code></pre> <p>Foi poss\u00edvel observar uma melhora significativa no silhouette score, de 0.2849 com PCA para 0.5928 com t-SNE, indicando uma estrutura de clusters muito mais definida.</p> <p>Os centr\u00f3ides na visualiza\u00e7\u00e3o t-SNE podem parecer \"estranhos\" porque esta t\u00e9cnica prioriza a preserva\u00e7\u00e3o de estruturas locais em detrimento de rela\u00e7\u00f5es globais e densidades. O t-SNE distorce intencionalmente o espa\u00e7o para destacar agrupamentos pr\u00f3ximos, o que explica a posi\u00e7\u00e3o n\u00e3o convencional dos centr\u00f3ides na visualiza\u00e7\u00e3o.</p> <p>Em resumo, o trade-off vale a pena: mesmo com a perda de informa\u00e7\u00f5es sobre densidades e estruturas globais, a qualidade da clusteriza\u00e7\u00e3o melhorou drasticamente, revelando padr\u00f5es que n\u00e3o eram aparentes com PCA.</p>"},{"location":"projeto2/main/#criando-a-coluna-da-variavel-alvo","title":"Criando a coluna da vari\u00e1vel-alvo","text":"<p>Agora, vamos criar a coluna que conter\u00e1 a vari\u00e1vel categ\u00f3rica <code>Wine_Type</code>, criada a partir da clusteriza\u00e7\u00e3o do K-Means com t-SNE. Essa coluna ser\u00e1 a vari\u00e1vel-alvo das an\u00e1lises preditivas feitas pelos modelos supervisionados adiante.</p> Sa\u00eddaC\u00f3digo <p>Distribui\u00e7\u00e3o dos clusters - Wine Type 1: 65 Wine Type 2: 51 Wine Type 3: 62</p> <pre><code>import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-clustering.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = scaler.fit_transform(df)\n\ntsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\nX_tsne = tsne.fit_transform(X)\n\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(X)\n\ndf[\"cluster\"] = cluster_labels\ndf[\"Wine_Type\"] = [f\"Wine Type {label + 1}\" for label in cluster_labels]\n\nprint(\"Distribui\u00e7\u00e3o dos clusters -&lt;br&gt;\")\nfor i in range(1, 4):\n    count = len(df[df['Wine_Type'] == f'Wine Type {i}'])\n    print(f\"Wine Type {i}: {count}&lt;br&gt;\")\n\n# Salvar para csv\n# df.to_csv(\"wine-final.csv\", index=False)\n</code></pre> <p>Com isso, podemos partir para as pr\u00f3ximas etapas.</p>"},{"location":"projeto2/main/#etapa-5-divisao-de-dados","title":"Etapa 5 - Divis\u00e3o de dados","text":"<p>Em seguida, vamos realizar a divis\u00e3o dos dados em conjuntos de treino e teste.</p> <ul> <li> <p>Conjunto de Treino: Utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: Utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, foi utilizada a fun\u00e7\u00e3o train_test_split() do <code>scikit-learn</code>. Os par\u00e2metros utilizados s\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> <li> <p>stratify=y: Esse atributo definido como y \u00e9 essencial devido \u00e0 natureza da coluna <code>Wine_Type</code>. Com essa defini\u00e7\u00e3o, ser\u00e1 mantida a mesma propor\u00e7\u00e3o das categorias em ambos os conjuntos, reduzindo o vi\u00e9s.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 142 amostras</p> <p>Teste: 36 amostras</p> <p>Propor\u00e7\u00e3o: 79.8% treino, 20.2% teste</p> <p>Distribui\u00e7\u00e3o das classes - </p> <p>Treino:</p> Wine_Type count Wine Type 1 52 Wine Type 3 49 Wine Type 2 41 <p>Teste:</p> Wine_Type count Wine Type 3 13 Wine Type 1 13 Wine Type 2 10 <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(\"Wine_Type\", axis=1)\nX = scaler.fit_transform(X)\ny = df[\"Wine_Type\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Treino: {X_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {X_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {X_train.shape[0]/X.shape[0]*100:.1f}% treino, {X_test.shape[0]/X.shape[0]*100:.1f}% teste\\n\")\n\nprint(\"Distribui\u00e7\u00e3o das classes - \\n\")\nprint(\"Treino:\\n\")\nprint(y_train.value_counts().to_markdown(), \"\\n\")\nprint(\"Teste:\\n\")\nprint(y_test.value_counts().to_markdown(), \"\\n\")\n</code></pre> <p>Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting.</p>"},{"location":"projeto2/main/#etapa-6-treinamento-do-modelo-random-forest","title":"Etapa 6 - Treinamento do Modelo Random Forest","text":"<p>Agora, vamos treinar um modelo de Random Forest para prever a vari\u00e1vel alvo <code>Wine_Type</code> para os dados do conjunto teste. Nosso objetivo aqui \u00e9 treinar e avaliar o modelo, para depois compar\u00e1-lo ao SVM e o KNN (feito no projeto anterior) e decidir o melhor para esta base.</p> Sa\u00eddaC\u00f3digo <p>Accuracy: 0.9722222222222222 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 9 Color_Intensity 0.181092 6 Flavanoids 0.164162 12 Proline 0.144578 11 OD280 0.134655 0 Alcohol 0.105019 10 Hue 0.066951 5 Total_Phenols 0.057426 4 Magnesium 0.036993 3 Ash_Alcanity 0.025609 8 Proanthocyanins 0.025300 1 Malic_Acid 0.024365 2 Ash 0.019025 7 Nonflavanoid_Phenols 0.014824 </p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nle = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\ny = le.fit_transform(df[\"Wine_Type\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nrf = RandomForestClassifier(n_estimators=100,\n                            max_depth=5,\n                            max_features='sqrt', \n                            random_state=42)\n\nrf.fit(X_train_scaled, y_train)\npredictions = rf.predict(X_test_scaled)\n\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n\nfeature_importance = pd.DataFrame({\n    \"Feature\": X_train.columns,\n    \"Import\u00e2ncia\": rf.feature_importances_\n})\n\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by=\"Import\u00e2ncia\", ascending=False).to_html() + \"&lt;br&gt;\")\n</code></pre>"},{"location":"projeto2/main/#etapa-7-avaliacao-do-modelo-random-forest","title":"Etapa 7 - Avalia\u00e7\u00e3o do Modelo Random Forest","text":"<p>Agora, vamos realizar a avalia\u00e7\u00e3o do modelo de Random Forest.</p>"},{"location":"projeto2/main/#acuracia","title":"Acur\u00e1cia","text":"<p>Coincidentemente, o modelo atingiu a mesma acur\u00e1cia do modelo KNN realizado anteriormente, de 97,22%. \u00c9 um \u00f3timo de valor de acur\u00e1cia, por\u00e9m, devemos realizar uma valida\u00e7\u00e3o cruzada novamente para garantir que n\u00e3o \u00e9 overfitting.</p>"},{"location":"projeto2/main/#acuracias-dos-conjuntos-e-validacao-cruzada","title":"Acur\u00e1cias dos conjuntos e valida\u00e7\u00e3o cruzada","text":"Sa\u00eddaC\u00f3digo <p>Acur\u00e1cias dos conjuntos - Random Forest</p> <p>Acur\u00e1cia no Treino: 1.0000 </p> <p>Acur\u00e1cia no Teste: 0.9722</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [1.         1.         1.         1.         0.94285714]</p> <p>M\u00e9dia: 0.9886 (+/- 0.0457)</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nle = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\ny = le.fit_transform(df[\"Wine_Type\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nrf = RandomForestClassifier(n_estimators=100,\n                            max_depth=5,\n                            max_features='sqrt', \n                            random_state=42)\n\nrf.fit(X_train_scaled, y_train)\npredictions = rf.predict(X_test_scaled)\n\ntrain_accuracy = rf.score(X_train_scaled, y_train)\ntest_accuracy = rf.score(X_test_scaled, y_test)\nprint(f\"\\n&lt;b&gt;Acur\u00e1cias dos conjuntos - Random Forest&lt;/b&gt;\\n\")\nprint(f\"Acur\u00e1cia no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"Acur\u00e1cia no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(rf, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>Com esses resultados, assim como aconteceu no KNN, podemos concluir que h\u00e1 muita chance desse n\u00e3o ser um caso de overfitting. Isso porque as acur\u00e1cias dos conjuntos s\u00e3o consistentes. Al\u00e9m disso, a valida\u00e7\u00e3o cruzada nos demonstrou uma alta m\u00e9dia, de 98,86%, um desvio padr\u00e3o baixo e uma varia\u00e7\u00e3o dos scores entre 94,28% \u00e0 100%, uma varia\u00e7\u00e3o normal. Considerando a natureza do dataset, que \u00e9 pequeno, bem separado e pouco ruidoso, o resultado \u00e9 coerente, e nenhum \"milagre\".</p>"},{"location":"projeto2/main/#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":"Matriz de Confus\u00e3oC\u00f3digo <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\nle = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\ny = le.fit_transform(df[\"Wine_Type\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nrf = RandomForestClassifier(n_estimators=100,\n                            max_depth=5,\n                            max_features='sqrt', \n                            random_state=42)\n\nrf.fit(X_train_scaled, y_train)\npredictions = rf.predict(X_test_scaled)\n\ncm = confusion_matrix(y_test, predictions)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\nplt.xlabel(\"Predito\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o - Random Forest\")\n\nplt.savefig(\"docs/projeto2/images/cm-rf.svg\", format=\"svg\", transparent=True)\nplt.close()\n\nreport_dict = classification_report(y_test, predictions, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\nprint(report_df.round(2).to_markdown())\n</code></pre> <p>O modelo atingiu uma performance excepcional, com acur\u00e1cia geral de 97%, classe 2 perfeitamente prevista pelo modelo com Precis\u00e3o, Recall e F1-Score de 1.00 e alta consist\u00eancia geral, j\u00e1 que todas classes possuem F1-Score acima de 0.94.</p>"},{"location":"projeto2/main/#metricas-de-qualidade","title":"M\u00e9tricas de qualidade","text":"precision recall f1-score support 0 0.93 1 0.96 13 1 1 0.89 0.94 9 2 1 1 1 14 accuracy 0.97 0.97 0.97 0.97 macro avg 0.98 0.96 0.97 36 weighted avg 0.97 0.97 0.97 36"},{"location":"projeto2/main/#etapa-8-treinamento-do-modelo-svm","title":"Etapa 8 - Treinamento do Modelo SVM","text":"<p>Agora, vamos treinar um modelo SVM para prever a vari\u00e1vel alvo <code>Wine_Type</code> para os dados do conjunto teste. Nosso objetivo aqui \u00e9 treinar e avaliar o modelo, para depois compar\u00e1-lo ao Random Forest e o KNN (feito no projeto anterior) e decidir o melhor para esta base. Para esse primeiro modelo SVM, vamos utilizar o kernel RBF (Radial Basis Function). Esse kernel mapeia os dados em um espa\u00e7o dimensional infinito por meio de uma fun\u00e7\u00e3o gaussiana. Esse kernel foi projetado para grandes volumes de dados, ent\u00e3o, caso haja algum problema, tamb\u00e9m podemos testar um SVM linear.</p> Sa\u00eddaC\u00f3digo <p>Acur\u00e1cia do SVM: 1.0</p> <p>Relat\u00f3rio de Classifica\u00e7\u00e3o:</p> precision recall f1-score support 0 1 1 1 13 1 1 1 1 9 2 1 1 1 14 accuracy 1 1 1 1 macro avg 1 1 1 36 weighted avg 1 1 1 36 <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\nle = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\ny = le.fit_transform(df[\"Wine_Type\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nsvm_model = SVC(kernel=\"rbf\", C=1, gamma=\"scale\")\n\nsvm_model.fit(X_train_scaled, y_train)\ny_pred = svm_model.predict(X_test_scaled)\n\nacc = accuracy_score(y_test, y_pred)\nprint(\"Acur\u00e1cia do SVM:\", acc)\n\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\\n\")\n\nreport_dict = classification_report(y_test, y_pred, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\nprint(report_df.round(2).to_markdown())\n</code></pre>"},{"location":"projeto2/main/#etapa-9-avaliacao-do-modelo-svm","title":"Etapa 9 - Avalia\u00e7\u00e3o do Modelo SVM","text":"<p>Agora, vamos realizar a avalia\u00e7\u00e3o do modelo de SVM com RBF.</p>"},{"location":"projeto2/main/#acuracia_1","title":"Acur\u00e1cia","text":"<p>O modelo atingiu a acur\u00e1cia de 100%. \u00c9 um valor de acur\u00e1cia perfeito, por\u00e9m, devemos realizar uma valida\u00e7\u00e3o cruzada novamente para garantir que n\u00e3o \u00e9 overfitting.</p> Sa\u00eddaC\u00f3digo <p>Acur\u00e1cias dos conjuntos - SVM RBF</p> <p>Acur\u00e1cia no Treino: 1.0000 </p> <p>Acur\u00e1cia no Teste: 1.0000</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.66666667 0.63888889 0.69444444 0.71428571 0.77142857]</p> <p>M\u00e9dia: 0.6971 (+/- 0.0901)</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nle = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\ny = le.fit_transform(df[\"Wine_Type\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nsvm_model = SVC(kernel=\"rbf\", C=1, gamma=\"scale\")\n\nsvm_model.fit(X_train_scaled, y_train)\ny_pred = svm_model.predict(X_test_scaled)\n\ntrain_accuracy = svm_model.score(X_train_scaled, y_train)\ntest_accuracy = svm_model.score(X_test_scaled, y_test)\nprint(f\"\\n&lt;b&gt;Acur\u00e1cias dos conjuntos - SVM RBF&lt;/b&gt;\\n\")\nprint(f\"Acur\u00e1cia no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"Acur\u00e1cia no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(svm_model, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>Como \u00e9 poss\u00edvel observar pela acur\u00e1cia dos folds, o modelo sofre de overfitting pesado, j\u00e1 que a m\u00e9dia de acur\u00e1cia ficou de 69,71%. Uma poss\u00edvel causa para esse problema \u00e9 o fato de que, anteriormente, foi criada a coluna <code>Wine_Type</code> atrav\u00e9s de um K-Means realizado em toda a base de dados, potencialmente vazando dados e causando a memoriza\u00e7\u00e3o do treino pelo modelo ao inv\u00e9s da aprendizagem e generaliza\u00e7\u00e3o real. Portanto, agora, vamos realizar direto uma valida\u00e7\u00e3o cruzada mas utilizando o kernel Linear para o SVM.</p> Sa\u00eddaC\u00f3digo <p>Acur\u00e1cias dos conjuntos - SVM linear</p> <p>Acur\u00e1cia no Treino: 1.0000 </p> <p>Acur\u00e1cia no Teste: 1.0000</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.91666667 0.94444444 1.         1.         0.97142857]</p> <p>M\u00e9dia: 0.9665 (+/- 0.0647)</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nle = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto/wine-final.csv\", sep=\",\", encoding=\"UTF8\")\n\nX = df.drop(columns=[\"Wine_Type\", \"cluster\"], axis=1)\ny = le.fit_transform(df[\"Wine_Type\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nsvm_model = SVC(kernel=\"linear\", C=1, gamma=\"scale\")\n\nsvm_model.fit(X_train_scaled, y_train)\ny_pred = svm_model.predict(X_test_scaled)\n\ntrain_accuracy = svm_model.score(X_train_scaled, y_train)\ntest_accuracy = svm_model.score(X_test_scaled, y_test)\nprint(f\"\\n&lt;b&gt;Acur\u00e1cias dos conjuntos - SVM linear&lt;/b&gt;\\n\")\nprint(f\"Acur\u00e1cia no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"Acur\u00e1cia no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(svm_model, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>O SVM com kernel RBF apresentou overfitting severo em valida\u00e7\u00e3o cruzada (\u224869,7%), enquanto a vers\u00e3o com kernel linear alcan\u00e7ou desempenho robusto (\u224896,6%), evidenciando que, para bases pequenas e aproximadamente lineares, a escolha do kernel \u00e9 determinante para a capacidade de generaliza\u00e7\u00e3o do modelo.</p>"},{"location":"projeto2/main/#matriz-de-confusao_1","title":"Matriz de Confus\u00e3o","text":"<p>Considerando que a acur\u00e1cia do modelo foi de 100%, n\u00e3o \u00e9 sequer necess\u00e1rio obsevar a matriz de confus\u00e3o. O modelo acertou em todos os casos. Todas as m\u00e9tricas foram perfeitas e, dessa vez, atrav\u00e9s do kernel linear, sem overfitting.</p>"},{"location":"projeto2/main/#etapa-10-conclusao-final","title":"Etapa 10 - Conclus\u00e3o Final","text":"<p>Os resultados evidenciam que, em bases pequenas, modelos excessivamente flex\u00edveis tendem a memorizar os dados, enquanto abordagens mais restritivas, como SVM Linear, KNN e Random Forest, apresentam melhor equil\u00edbrio entre vi\u00e9s e vari\u00e2ncia.</p> <p>Em termos de desempenho, considerando a m\u00e9dia da acur\u00e1cia obtida por valida\u00e7\u00e3o cruzada, o SVM Linear apresentou 96,65%, enquanto o Random Forest atingiu a maior m\u00e9dia, com 98,86%. O modelo KNN, por sua vez, apresentou desempenho satisfat\u00f3rio, com m\u00e9dia de 95,52%.</p> <p>Diante desses resultados, conclui-se que o modelo Random Forest \u00e9 o mais adequado para a previs\u00e3o do tipo de vinho nesta base, por apresentar o melhor desempenho m\u00e9dio aliado a maior robustez e estabilidade na generaliza\u00e7\u00e3o.</p>"},{"location":"projeto3/main/","title":"Projeto Integrado","text":""},{"location":"projeto3/main/#modelo-de-machine-learning-k-means-random-forest-e-svm","title":"Modelo de Machine Learning - K-means, Random Forest e SVM","text":"<p>Para esse projeto, foi utilizado um dataset obtido no Projeto Integrado, na raspagem do site da Growth.</p>"},{"location":"projeto3/main/#objetivo","title":"Objetivo","text":"<p>O dataset possui informa\u00e7\u00f5es sobre diversos produtos da Growth. O objetivo da an\u00e1lise ser\u00e1 prever o qu\u00e3o recomendado ser\u00e1 um produto de acordo com as outras informa\u00e7\u00f5es da base.</p>"},{"location":"projeto3/main/#workflow","title":"Workflow","text":"<p>Os pontos \"etapas\" s\u00e3o o passo-a-passo da realiza\u00e7\u00e3o do projeto.</p>"},{"location":"projeto3/main/#etapa-1-exploracao-de-dados","title":"Etapa 1 - Explora\u00e7\u00e3o de Dados","text":"<p>Primeiramente, para entender melhor a base de dados, vamos descobrir quantas linhas e colunas o dataset possui.</p> Sa\u00eddaC\u00f3digo <p>(182, 14)</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\nprint(df.shape)\n</code></pre> <p>Como foi poss\u00edvel observar no c\u00f3digo acima, o dataset possui 182 linhas e 14 colunas, com cada linha possuindo os dados de um produto.</p>"},{"location":"projeto3/main/#colunas-do-dataset","title":"Colunas do Dataset","text":"<p>Em seguida, \u00e9 necess\u00e1rio descobrir a natureza dos dados. Isso ser\u00e1 feito rodando as linhas de c\u00f3digo abaixo:</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\nprint(df.info())\n</code></pre> <p>As informa\u00e7\u00f5es obtidas foram as seguintes:</p> Coluna Tipo Descri\u00e7\u00e3o <code>nome</code> String Nome do produto <code>preco</code> String Pre\u00e7o do produto <code>estrelas_media</code> String M\u00e9dia de estrelas do produto <code>avaliacoes</code> Inteiro Total de avalia\u00e7\u00f5es realizadas por usu\u00e1rios do produto <code>recomendacoes</code> Inteiro Porcentagem de recomenda\u00e7\u00f5es do produto <code>formato</code> String Formato do produto (Ex: P\u00f3, L\u00edquido, Alimento, etc.) <code>aminoacidos</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria aminoacidos <code>carboidratos</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria carboidratos <code>clinical</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria clinical <code>proteinas</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria proteinas <code>termogenicos</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria termogenicos <code>veganos</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria veganos <code>vegetarianos</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria vegetarianos <code>vitaminas</code> Inteiro Vari\u00e1vel bin\u00e1ria que indica se o produto possui a categoria vitaminas"},{"location":"projeto3/main/#visualizacao-das-variaveis","title":"Visualiza\u00e7\u00e3o das vari\u00e1veis","text":"<p>Em seguida, \u00e9 essencial realizar gr\u00e1ficos para visualizar como cada uma das vari\u00e1veis se comportam, com o objetivo de entender melhor a base da dados. Todas vari\u00e1veis da base s\u00e3o quantitativas, sendo onze cont\u00ednuas e duas discretas.</p>"},{"location":"projeto3/main/#variaveis-quantitativas-continuas","title":"Vari\u00e1veis Quantitativas Cont\u00ednuas","text":"precoestrelas_mediaavaliacoes Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:55.658241 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\n\nplt.figure(figsize=(8,6))\nsns.scatterplot(data=df, x=\"preco\", y=\"recomendacoes\")\nplt.title(\"Distribui\u00e7\u00e3o entre Pre\u00e7o e Recomenda\u00e7\u00f5es\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:55.794912 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\nplt.figure(figsize=(8,6))\nsns.scatterplot(data=df, x=\"estrelas_media\", y=\"recomendacoes\", color=\"orange\")\nplt.title(\"Distribui\u00e7\u00e3o entre M\u00e9dia de Estrelas e Recomenda\u00e7\u00f5es\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:55.929450 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\nplt.figure(figsize=(8,6))\nsns.scatterplot(data=df, x=\"avaliacoes\", y=\"recomendacoes\", color=\"lightgreen\")\nplt.title(\"Distribui\u00e7\u00e3o entre Total de Avalia\u00e7\u00f5es e Recomenda\u00e7\u00f5es\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre>"},{"location":"projeto3/main/#variavel-quantitativa-discreta-recomendacoes","title":"Vari\u00e1vel Quantitativa Discreta <code>recomendacoes</code>","text":"Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:56.090098 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\nsns.histplot(data=df, x=\"recomendacoes\", bins=20)\nplt.title(\"Histograma de Recomenda\u00e7\u00f5es\")\nplt.xlabel(\"Recomenda\u00e7\u00f5es\")\nplt.ylabel(\"Frequ\u00eancia\")\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre>"},{"location":"projeto3/main/#variaveis-qualitativas-nominais","title":"Vari\u00e1veis Qualitativas Nominais","text":"formatocategorias (todas as 8 vari\u00e1veis) Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:56.269495 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\nplt.figure(figsize=(10, 6))\nsns.countplot(data=df, x=\"formato\", color=\"salmon\")\n\nplt.title(\"Frequ\u00eancia de Produtos por Formato\")\nplt.xlabel(\"Formato\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.xticks(rotation=45)\nplt.tight_layout()\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> Gr\u00e1ficoC\u00f3digo 2025-12-10T13:51:56.454483 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\n\ncategorias = [\"aminoacidos\", \"carboidratos\", \"clinical\", \"proteinas\", \"termogenicos\", \"veganos\", \"vegetarianos\", \"vitaminas\"]\n\nfreq = df[categorias].sum().reset_index()\nfreq.columns = [\"categoria\", \"frequencia\"]\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=freq, x=\"categoria\", y=\"frequencia\", color=\"orange\")\n\nplt.title(\"Frequ\u00eancia de Presen\u00e7a das Categorias nos Produtos\")\nplt.xlabel(\"Categoria\")\nplt.ylabel(\"N\u00famero de Produtos\")\nplt.xticks(rotation=45)\nplt.tight_layout()\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=False)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> <p>Aqui obtemos informa\u00e7\u00f5es valiosas. Principalmente, que a coluna <code>avaliacoes</code> possui outliers e que a vari\u00e1vel-alvo <code>recomendacoes</code> possui valores zerados.</p>"},{"location":"projeto3/main/#etapa-2-pre-processamento","title":"Etapa 2 - Pr\u00e9-processamento","text":""},{"location":"projeto3/main/#1-passo-identificacao-de-valores-nulos","title":"1\u00b0 Passo: Identifica\u00e7\u00e3o de valores nulos","text":"<p>Atrav\u00e9s da linha de c\u00f3digo abaixo, pode-se identificar que n\u00e3o h\u00e1 valores nulos na base. Portanto, pularemos o passo de tratamento de valores nulos.</p> <pre><code>print(df.isnull().sum())\n</code></pre> <p>N\u00e3o h\u00e1 valores nulos no dataset, contanto, a vari\u00e1vel-alvo <code>recomendacoes</code>, como pudemos observar nas visualiza\u00e7\u00f5es, possui valores zerados. Rodando esse c\u00f3digo, obtemos 14 registros, que representa menos de 10% da base. Portanto, vamos remover esses valores da base atrav\u00e9s do c\u00f3digo abaixo:</p> <pre><code>droppar = []\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\n</code></pre>"},{"location":"projeto3/main/#2-passo-remocao-de-colunas-desimportantes","title":"2\u00b0 Passo: Remo\u00e7\u00e3o de colunas desimportantes","text":"<p>Vamos remover a vari\u00e1vel <code>nome</code> da base, j\u00e1 que ela n\u00e3o contribuir\u00e1 para as predi\u00e7\u00f5es.</p> <pre><code>df = df.drop(\"nome\", axis=1)\n</code></pre>"},{"location":"projeto3/main/#3-passo-correcao-dos-tipos-de-dados","title":"3\u00b0 Passo: Corre\u00e7\u00e3o dos tipos de dados","text":"<p>As colunas <code>preco</code> e <code>estrelas_media</code> deveriam ser float, contudo, est\u00e3o como object devido \u00e0 separa\u00e7\u00e3o dos decimais por \",\". Vamos resolver isso:</p> <pre><code>df[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n</code></pre>"},{"location":"projeto3/main/#4-passo-padronizacao-das-features-numericas","title":"4\u00b0 Passo: Padroniza\u00e7\u00e3o das features num\u00e9ricas","text":"<p>Agora, \u00e9 necess\u00e1rio padronizar as features num\u00e9ricas da base. Para as vari\u00e1veis quantitativas n\u00e3o desbalancearem os c\u00e1lculos dos modelos. Para a padroniza\u00e7\u00e3o, foi utilizado o StandardScaler() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\n</code></pre>"},{"location":"projeto3/main/#5-passo-codificacao-de-variaveis-categoricas","title":"5\u00b0 Passo: Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>Por fim, vamos codificar as vari\u00e1veis categ\u00f3ricas. Utilizaremos a t\u00e9cnica de One-Hot Encoding para codificar essas vari\u00e1veis, utilizando o OneHotEncoder() do <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\n\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n</code></pre>"},{"location":"projeto3/main/#codigo-final-do-pre-processamento","title":"C\u00f3digo Final do Pr\u00e9-processamento","text":"<pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nprint(X.shape)\nprint(X.head())\n</code></pre>"},{"location":"projeto3/main/#etapa-3-divisao-de-dados","title":"Etapa 3 - Divis\u00e3o de dados","text":"<p>Em seguida, vamos realizar a divis\u00e3o dos dados em conjuntos de treino e teste.</p> <ul> <li> <p>Conjunto de Treino: Utilizado para ensinar o modelo a reconhecer padr\u00f5es</p> </li> <li> <p>Conjunto de Teste: Utilizado para avaliar o desempenho do modelo com dados ainda n\u00e3o vistos</p> </li> </ul> <p>Para realizar a divis\u00e3o, foi utilizada a fun\u00e7\u00e3o train_test_split() do <code>scikit-learn</code>. Os par\u00e2metros utilizados s\u00e3o:</p> <ul> <li> <p>test_size=0.2: Define que 20% dos dados ser\u00e3o utilizados para teste, enquanto o restante ser\u00e1 usado para treino.</p> </li> <li> <p>random_state=42: Par\u00e2metro que controla o gerador de n\u00famero aleat\u00f3rios utilizado para sortear os dados antes de separ\u00e1-los. Garante reprodutibilidade.</p> </li> </ul> Sa\u00eddaC\u00f3digo <p>Treino: 136 amostras</p> <p>Teste: 34 amostras</p> <p>Propor\u00e7\u00e3o: 80.0% treino, 20.0% teste</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Treino: {X_train.shape[0]} amostras\\n\")\nprint(f\"Teste: {X_test.shape[0]} amostras\\n\")\nprint(f\"Propor\u00e7\u00e3o: {X_train.shape[0]/X.shape[0]*100:.1f}% treino, {X_test.shape[0]/X.shape[0]*100:.1f}% teste\\n\")\n</code></pre> <p>Esta divis\u00e3o adequada \u00e9 de extrema import\u00e2ncia, pois ajuda a evitar overfitting.</p>"},{"location":"projeto3/main/#etapa-4-regressao-linear-multipla","title":"Etapa 4 - Regress\u00e3o Linear M\u00faltipla","text":"<p>Agora, vamos fazer um modelo de Regress\u00e3o Linear M\u00faltipla com a base.</p>"},{"location":"projeto3/main/#multicolinearidade","title":"Multicolinearidade","text":"<p>Primeiramente, vamos checar por Multicolinearidade no modelo para garantir que as vari\u00e1veis independentes n\u00e3o tenham seus coeficientes inflados por correla\u00e7\u00f5es entre si:</p> Variavel VIF 0 preco 1.08616 1 estrelas_media 1.02763 2 avaliacoes 1.10846 <p>Como todos valores est\u00e3o abaixo de 5, inclusive, muito pr\u00f3ximos do ideal de 1, n\u00e3o h\u00e1 multicolinearidade no modelo, ent\u00e3o n\u00e3o precisamos retirar vari\u00e1veis.</p>"},{"location":"projeto3/main/#stepwise","title":"Stepwise","text":"<p>Iremos realizar o M\u00e9todo de Sele\u00e7\u00e3o de Vari\u00e1veis para deixar no modelo apenas as vari\u00e1veis relevantes para a predi\u00e7\u00e3o (e que n\u00e3o tenham correla\u00e7\u00e3o esp\u00faria).</p> Sa\u00eddaC\u00f3digo <p>Vari\u00e1veis selecionadas (Backward): ['preco', 'estrelas_media', 'formato_Comprimido', 'formato_C\u00e1psula', 'formato_P\u00f3']</p> <pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\ndef r2_adj(r2, n, k):\n    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n\ndef stepwise_backward(X, y):\n    selecionadas = list(X.columns)\n    n = len(y)\n    modelo_inicial = LinearRegression().fit(X, y)\n    melhor_r2_adj = r2_adj(modelo_inicial.score(X, y), n, len(selecionadas))\n\n    melhorou = True\n\n    while melhorou and len(selecionadas) &gt; 1:\n        r2_adj_temp = []\n        for var in selecionadas:\n            teste_vars_sel = [v for v in selecionadas if v != var]\n            modelo = LinearRegression().fit(X[teste_vars_sel], y)\n            r2 = modelo.score(X[teste_vars_sel], y)\n            r2_adj_temp.append((var, r2_adj(r2, n, len(teste_vars_sel))))\n\n        pior_var, melhor_r2 = max(r2_adj_temp, key=lambda x: x[1])\n\n        if melhor_r2 &gt; melhor_r2_adj:\n            melhor_r2_adj = melhor_r2\n            selecionadas.remove(pior_var)\n        else:\n            melhorou = False\n\n    return selecionadas\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nvars_sel = stepwise_backward(X_train, y_train)\nprint(\"Vari\u00e1veis selecionadas (Backward):\")\nprint(vars_sel)\n</code></pre>"},{"location":"projeto3/main/#modelo-final","title":"Modelo Final","text":"<p>Agora, finalmente, vamos rodar o modelo final, checar os coeficientes e o R\u00b2:</p> Sa\u00eddaC\u00f3digo <p>Coeficientes da regress\u00e3o:</p> <p>Intercepto = 94.7097</p> <p>preco = -0.2528</p> <p>estrelas_media = 3.9724</p> <p>formato_Comprimido = 0.562</p> <p>formato_C\u00e1psula = 0.9323</p> <p>formato_P\u00f3 = 0.9621</p> <p>R\u00b2 do modelo no conjunto de teste: 0.92</p> <pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\ndef r2_adj(r2, n, k):\n    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n\ndef stepwise_backward(X, y):\n    selecionadas = list(X.columns)\n    n = len(y)\n    modelo_inicial = LinearRegression().fit(X, y)\n    melhor_r2_adj = r2_adj(modelo_inicial.score(X, y), n, len(selecionadas))\n\n    melhorou = True\n\n    while melhorou and len(selecionadas) &gt; 1:\n        r2_adj_temp = []\n        for var in selecionadas:\n            teste_vars_sel = [v for v in selecionadas if v != var]\n            modelo = LinearRegression().fit(X[teste_vars_sel], y)\n            r2 = modelo.score(X[teste_vars_sel], y)\n            r2_adj_temp.append((var, r2_adj(r2, n, len(teste_vars_sel))))\n\n        pior_var, melhor_r2 = max(r2_adj_temp, key=lambda x: x[1])\n\n        if melhor_r2 &gt; melhor_r2_adj:\n            melhor_r2_adj = melhor_r2\n            selecionadas.remove(pior_var)\n        else:\n            melhorou = False\n\n    return selecionadas\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nvars_sel = stepwise_backward(X_train, y_train)\n\nrlm = LinearRegression()\nrlm.fit(X_train[vars_sel], y_train)\n\ncoeficientes = rlm.coef_\nvariaveis = vars_sel\n\nprint(\"\\n&lt;b&gt;Coeficientes da regress\u00e3o:&lt;/b&gt;\\n\")\nprint(f\"Intercepto = {round(rlm.intercept_, 4)}\\n\")\nfor i in range(len(coeficientes)):\n    print(f\"{variaveis[i]} = {round(coeficientes[i], 4)}\\n\")\n\ny_pred = rlm.predict(X_test[vars_sel])\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"\\n&lt;b&gt;R\u00b2 do modelo no conjunto de teste: {round(r2, 4)}&lt;/b&gt;\")\n</code></pre> <p>O R\u00b2 do modelo foi \u00f3timo, de 92%, significando que a regress\u00e3o linear realizada possui uma forte capacidade de explica\u00e7\u00e3o da varia\u00e7\u00e3o da vari\u00e1vel <code>recomendacoes</code> atrav\u00e9s das vari\u00e1veis selecionadas no stepwise. </p>"},{"location":"projeto3/main/#validacao-cruzada","title":"Valida\u00e7\u00e3o Cruzada","text":"<p>Contanto, devido ao alto valor de R\u00b2, surge uma suspeita de overfitting no modelo. Vamos fazer uma valida\u00e7\u00e3o cruzada para validar essa hip\u00f3tese:</p> Sa\u00eddaC\u00f3digo <p>R\u00b2 dos conjuntos - Regress\u00e3o Linear M\u00faltipla</p> <p>R\u00b2 no Treino: 0.9037 </p> <p>R\u00b2 no Teste: 0.9200</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.91729168 0.9169919  0.85917928 0.84052879 0.63885196]</p> <p>M\u00e9dia: 0.8346 (+/- 0.2051)</p> <pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\ndef r2_adj(r2, n, k):\n    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n\ndef stepwise_backward(X, y):\n    selecionadas = list(X.columns)\n    n = len(y)\n    modelo_inicial = LinearRegression().fit(X, y)\n    melhor_r2_adj = r2_adj(modelo_inicial.score(X, y), n, len(selecionadas))\n\n    melhorou = True\n\n    while melhorou and len(selecionadas) &gt; 1:\n        r2_adj_temp = []\n        for var in selecionadas:\n            teste_vars_sel = [v for v in selecionadas if v != var]\n            modelo = LinearRegression().fit(X[teste_vars_sel], y)\n            r2 = modelo.score(X[teste_vars_sel], y)\n            r2_adj_temp.append((var, r2_adj(r2, n, len(teste_vars_sel))))\n\n        pior_var, melhor_r2 = max(r2_adj_temp, key=lambda x: x[1])\n\n        if melhor_r2 &gt; melhor_r2_adj:\n            melhor_r2_adj = melhor_r2\n            selecionadas.remove(pior_var)\n        else:\n            melhorou = False\n\n    return selecionadas\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nvars_sel = stepwise_backward(X_train, y_train)\n\nrlm = LinearRegression()\nrlm.fit(X_train[vars_sel], y_train)\n\ntrain_accuracy = rlm.score(X_train[vars_sel], y_train)\ntest_accuracy = rlm.score(X_test[vars_sel], y_test)\nprint(f\"\\n&lt;b&gt;R\u00b2 dos conjuntos - Regress\u00e3o Linear M\u00faltipla&lt;/b&gt;\\n\")\nprint(f\"R\u00b2 no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"R\u00b2 no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(rlm, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>A varia\u00e7\u00e3o do R\u00b2 entre o conjunto de treino e de teste foi de apenas 1,63%, indicando que n\u00e3o h\u00e1 overfitting. Contanto, podemos observar que um dos folds obteve R\u00b2 de 63,88%, enquanto o resto variou entre bons valores, de 84% \u00e0 91%. Isso pode indicar que h\u00e1 instabilidade nos dados da base, com uma quantidade consider\u00e1vel de ru\u00eddo e dataset com poucos registros.</p>"},{"location":"projeto3/main/#etapa-5-treinamento-do-modelo-random-forest","title":"Etapa 5 - Treinamento do Modelo Random Forest","text":"<p>Agora, vamos realizar o treinamento do modelo Random Forest.</p> Sa\u00eddaC\u00f3digo <p>R\u00b2: 0.8907227042572403 RMSE: 1.4344827063137235 Import\u00e2ncia das Features:</p> Feature Import\u00e2ncia 1 estrelas_media 0.679035 2 avaliacoes 0.115709 0 preco 0.110327 5 formato_C\u00e1psula 0.030589 3 formato_Alimento 0.027951 7 formato_P\u00f3 0.025256 4 formato_Comprimido 0.009234 6 formato_L\u00edquido 0.001899 <p></p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import root_mean_squared_error, r2_score\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf = RandomForestRegressor(n_estimators=300,\n                            max_depth=None,\n                            max_features=\"log2\",\n                            random_state=42)\n\nrf.fit(X_train, y_train)\npredictions = rf.predict(X_test)\n\nprint(\"R\u00b2:\", r2_score(y_test, predictions))\nprint(\"RMSE:\", root_mean_squared_error(y_test, predictions))\n\nfeature_importance = pd.DataFrame({\n    \"Feature\": X_train.columns,\n    \"Import\u00e2ncia\": rf.feature_importances_\n})\n\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by=\"Import\u00e2ncia\", ascending=False).to_html() + \"&lt;br&gt;\")\n</code></pre>"},{"location":"projeto3/main/#etapa-6-avaliacao-do-modelo-random-forest","title":"Etapa 6 - Avalia\u00e7\u00e3o do Modelo Random Forest","text":"<p>Obtivemos um bom R\u00b2, de 91,39%, o que significa que o modelo de Random Forest consegue explicar 91,39% da varia\u00e7\u00e3o de <code>recomendacoes</code>. Al\u00e9m disso, o RMSE foi de 1.27, um bom valor para uma vari\u00e1vel que varia de 0 a 100. Ele significa que, em m\u00e9dia, a predi\u00e7\u00e3o erra em 1.27 pontos percentuais de recomenda\u00e7\u00f5es.</p> <p>Pudemos observar que, por uma imensa margem, a vari\u00e1vel mais importante do modelo \u00e9 <code>estrelas_media</code>. O restante possui pouco poder explicativo, mas devem ser mantidas para fazer ajuste fino dos valores preditos.</p>"},{"location":"projeto3/main/#validacao-cruzada_1","title":"Valida\u00e7\u00e3o Cruzada","text":"<p>Antes de seguirmos, vamos fazer uma r\u00e1pida valida\u00e7\u00e3o cruzada para garantir que n\u00e3o h\u00e1 overfitting.</p> Sa\u00eddaC\u00f3digo <p>R\u00b2 dos conjuntos - Random Forest</p> <p>R\u00b2 no Treino: 0.9778 </p> <p>R\u00b2 no Teste: 0.8907</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.8393821  0.84465885 0.85379156 0.79984857 0.61656171]</p> <p>M\u00e9dia: 0.7908 (+/- 0.1781)</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf = RandomForestRegressor(n_estimators=300,\n                            max_depth=None,\n                            max_features=\"log2\",\n                            random_state=42)\n\nrf.fit(X_train, y_train)\n\ntrain_accuracy = rf.score(X_train, y_train)\ntest_accuracy = rf.score(X_test, y_test)\nprint(f\"\\n&lt;b&gt;R\u00b2 dos conjuntos - Random Forest&lt;/b&gt;\\n\")\nprint(f\"R\u00b2 no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"R\u00b2 no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(rf, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>Podemos observar que sim, o modelo sofre de overfitting. A R\u00b2 no treino \u00e9 de 97,78%, por\u00e9m, no teste, cai significativamente, para 89,07%. Al\u00e9m disso, a m\u00e9dia de R\u00b2 dos folds foi de 79,08%, chegando a ter um fold com apenas 61,65% de R\u00b2. </p> <p>Mesmo ap\u00f3s alguns testes, n\u00e3o consegui reduzir o overfitting. Por isso, podemos concluir que o Random Forest n\u00e3o \u00e9 o melhor modelo para esse problema. Provavelmente, isso acontece devido \u00e0 combina\u00e7\u00e3o dos seguintes fatores:</p> <ul> <li> <p>Dataset pequeno: Random Forest costuma precisar de muitos dados para n\u00e3o oscilar entre folds;</p> </li> <li> <p>Target com varia\u00e7\u00e3o baixa: O modelo se confude ao tentar fazer splits certeiros;</p> </li> <li> <p>Ru\u00eddo no dataset: \u00c1rvores podem amplificar poss\u00edvel ru\u00eddo na base.</p> </li> </ul>"},{"location":"projeto3/main/#etapa-7-treinamento-do-modelo-svm","title":"Etapa 7 - Treinamento do Modelo SVM","text":"<p>Considerando que a base \u00e9 pequena, e relembrando do aprendizado do Projeto Extra, vamos diretamente utilizar o kernel linear para fazer o modelo.</p> Sa\u00eddaC\u00f3digo <p>R\u00b2: 0.9215875302645962 RMSE: 1.2151304774232532</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import root_mean_squared_error, r2_score\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nsvm = SVR(\n    kernel=\"linear\",\n    C=10,\n    epsilon=1.1\n)\n\nsvm.fit(X_train, y_train)\npred = svm.predict(X_test)\n\nprint(\"R\u00b2:\", r2_score(y_test, pred))\nprint(\"RMSE:\", root_mean_squared_error(y_test, pred))\n</code></pre>"},{"location":"projeto3/main/#etapa-8-avaliacao-do-modelo-svm","title":"Etapa 8 - Avalia\u00e7\u00e3o do Modelo SVM","text":"<p>Obtivemos um \u00f3timo R\u00b2, de 92,16%, o que significa que o modelo de SVM consegue explicar 92,16% da varia\u00e7\u00e3o de <code>recomendacoes</code>. Al\u00e9m disso, o RMSE foi de 1.21, um bom valor para uma vari\u00e1vel que varia de 0 a 100. Ele significa que, em m\u00e9dia, a predi\u00e7\u00e3o erra em 1.21 pontos percentuais de recomenda\u00e7\u00f5es.</p>"},{"location":"projeto3/main/#validacao-cruzada_2","title":"Valida\u00e7\u00e3o cruzada","text":"<p>Vamos testar novamente overfitting no modelo:</p> Sa\u00eddaC\u00f3digo <p>R\u00b2 dos conjuntos - SVM</p> <p>R\u00b2 no Treino: 0.9034 </p> <p>R\u00b2 no Teste: 0.9216</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.92277626 0.92195879 0.86662034 0.83739854 0.65759323]</p> <p>M\u00e9dia: 0.8413 (+/- 0.1950)</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVR\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nsvm = SVR(\n    kernel=\"linear\",\n    C=10,\n    epsilon=1.1\n)\n\nsvm.fit(X_train, y_train)\n\ntrain_accuracy = svm.score(X_train, y_train)\ntest_accuracy = svm.score(X_test, y_test)\nprint(f\"\\n&lt;b&gt;R\u00b2 dos conjuntos - SVM&lt;/b&gt;\\n\")\nprint(f\"R\u00b2 no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"R\u00b2 no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(svm, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>Dessa vez, parece que n\u00e3o h\u00e1 overfitting no modelo, j\u00e1 que obtivemos R\u00b2 de 90,34% no conjunto treino e 92,16% no conjunto teste. Novamente, o mesmo sinal de instabilidade na base observado na Regress\u00e3o Linear M\u00faltipla aparece aqui, com varia\u00e7\u00e3o alta entre os folds mesmo sem o modelo sofrer de overfitting.</p>"},{"location":"projeto3/main/#etapa-9-treinamento-do-modelo-knn","title":"Etapa 9 - Treinamento do Modelo KNN","text":"<p>Agora, vamos fazer o treinamento do modelo KNN.</p> Sa\u00eddaC\u00f3digo <p>K = 3 -&gt; R\u00b2 = 0.8961 K = 5 -&gt; R\u00b2 = 0.9129 K = 7 -&gt; R\u00b2 = 0.9090 K = 9 -&gt; R\u00b2 = 0.9027 K = 11 -&gt; R\u00b2 = 0.8935 K = 13 -&gt; R\u00b2 = 0.8877 K = 15 -&gt; R\u00b2 = 0.8813</p> <p>Melhor K encontrado: 5 Melhor R\u00b2 obtido: 0.9128744036979265</p> <p>--- Resultados do modelo final --- R\u00b2: 0.9128744036979265 RMSE: 1.280864618065761</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import r2_score, root_mean_squared_error\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmelhor_k = None\nmelhor_r2 = -999\nresultados = []\n\nfor k in [3, 5, 7, 9, 11, 13, 15]:\n    knn = KNeighborsRegressor(n_neighbors=k, weights=\"distance\", p=2)\n    knn.fit(X_train, y_train)\n\n    y_pred = knn.predict(X_test)\n    r2 = r2_score(y_test, y_pred)\n\n    resultados.append((k, r2))\n\n    print(f\"K = {k} -&gt; R\u00b2 = {r2:.4f}\")\n\n    if r2 &gt; melhor_r2:\n        melhor_r2 = r2\n        melhor_k = k\n\nprint(\"\\nMelhor K encontrado:\", melhor_k)\nprint(\"Melhor R\u00b2 obtido:\", melhor_r2)\n\nknn_final = KNeighborsRegressor(n_neighbors=melhor_k, weights=\"distance\", p=2)\nknn_final.fit(X_train, y_train)\ny_pred_final = knn_final.predict(X_test)\n\nprint(\"\\n--- Resultados do modelo final ---\")\nprint(\"R\u00b2:\", r2_score(y_test, y_pred_final))\nprint(\"RMSE:\", root_mean_squared_error(y_test, y_pred_final))\n</code></pre>"},{"location":"projeto3/main/#etapa-10-avaliacao-do-modelo-knn","title":"Etapa 10 - Avalia\u00e7\u00e3o do Modelo KNN","text":"<p>Obtivemos um bom R\u00b2, de 91,28%, o que significa que o modelo de KNN consegue explicar 91,28% da varia\u00e7\u00e3o de <code>recomendacoes</code>. Al\u00e9m disso, o RMSE foi de 1.28, um bom valor para uma vari\u00e1vel que varia de 0 a 100. Ele significa que, em m\u00e9dia, a predi\u00e7\u00e3o erra em 1.28 pontos percentuais de recomenda\u00e7\u00f5es.</p>"},{"location":"projeto3/main/#validacao-cruzada_3","title":"Valida\u00e7\u00e3o cruzada","text":"<p>Agora, vamos para o momento cr\u00edtico novamente. Apesar do SVM n\u00e3o ter tido overfitting, podemos ver se o KNN n\u00e3o sofre com o ru\u00eddo presente na base.</p> Sa\u00eddaC\u00f3digo <p>K = 3 -&gt; R\u00b2 = 0.8961 K = 5 -&gt; R\u00b2 = 0.9129 K = 7 -&gt; R\u00b2 = 0.9090 K = 9 -&gt; R\u00b2 = 0.9027 K = 11 -&gt; R\u00b2 = 0.8935 K = 13 -&gt; R\u00b2 = 0.8877 K = 15 -&gt; R\u00b2 = 0.8813</p> <p>Melhor K encontrado: 5 Melhor R\u00b2 obtido: 0.9128744036979265</p> <p>R\u00b2 dos conjuntos - KNN</p> <p>R\u00b2 no Treino: 1.0000 </p> <p>R\u00b2 no Teste: 0.9129</p> <p>Valida\u00e7\u00e3o Cruzada (5-fold) -</p> <p>Scores: [0.6469544  0.88900489 0.85580096 0.79865569 0.5332986 ]</p> <p>M\u00e9dia: 0.7447 (+/- 0.2688)</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import r2_score\n\nencoder = OneHotEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"docs/projeto3/produtos.csv\", sep=\";\", encoding=\"UTF8\")\ndroppar = []\n\nfeatures_num = [\"preco\", \"estrelas_media\", \"avaliacoes\"]\n\nfor i in range(len(df)):\n    if df.loc[i, \"recomendacoes\"] == 0:\n        droppar.append(i)\n\ndf = df.drop(index=droppar)\ndf = df.drop(\"nome\", axis=1)\n\ndf[\"preco\"] = df[\"preco\"].str.replace(\",\", \".\").astype(float)\ndf[\"estrelas_media\"] = df[\"estrelas_media\"].str.replace(\",\", \".\").astype(float)\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df[features_num]), columns=features_num, index=df.index)\ndf_encoded = encoder.fit_transform(df[[\"formato\"]]).toarray()\ndf_encoded = pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out([\"formato\"]), index=df.index)\n\nX = pd.concat([df_scaled, df_encoded], axis=1)\ny = df[\"recomendacoes\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmelhor_k = None\nmelhor_r2 = -999\nresultados = []\n\nfor k in [3, 5, 7, 9, 11, 13, 15]:\n    knn = KNeighborsRegressor(n_neighbors=k, weights=\"distance\", p=2)\n    knn.fit(X_train, y_train)\n\n    y_pred = knn.predict(X_test)\n    r2 = r2_score(y_test, y_pred)\n\n    resultados.append((k, r2))\n\n    print(f\"K = {k} -&gt; R\u00b2 = {r2:.4f}\")\n\n    if r2 &gt; melhor_r2:\n        melhor_r2 = r2\n        melhor_k = k\n\nprint(\"\\nMelhor K encontrado:\", melhor_k)\nprint(\"Melhor R\u00b2 obtido:\", melhor_r2)\n\nknn_final = KNeighborsRegressor(n_neighbors=melhor_k, weights=\"distance\", p=2)\nknn_final.fit(X_train, y_train)\n\ntrain_accuracy = knn_final.score(X_train, y_train)\ntest_accuracy = knn_final.score(X_test, y_test)\nprint(f\"\\n&lt;b&gt;R\u00b2 dos conjuntos - KNN&lt;/b&gt;\\n\")\nprint(f\"R\u00b2 no Treino: {train_accuracy:.4f} \\n\")\nprint(f\"R\u00b2 no Teste: {test_accuracy:.4f}\")\n\ncv_scores = cross_val_score(knn_final, X, y, cv=5)\nprint(f\"\\n&lt;b&gt;Valida\u00e7\u00e3o Cruzada (5-fold) -&lt;/b&gt;\\n\")\nprint(f\"Scores: {cv_scores}\\n\")\nprint(f\"M\u00e9dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n</code></pre> <p>Novamente, houve overfitting no modelo, com uma varia\u00e7\u00e3o de R\u00b2 entre o conjunto treino e teste de aproximadamente 8,5%. Al\u00e9m disso, os folds ainda possuem uma enorme varia\u00e7\u00e3o no valor de R\u00b2, indicando que a instabilidade dos dados tamb\u00e9m afeta o KNN.</p>"},{"location":"projeto3/main/#etapa-11-conclusao-final","title":"Etapa 11 - Conclus\u00e3o Final","text":"<p>O objetivo deste projeto foi prever o percentual de recomenda\u00e7\u00f5es dos produtos da Growth a partir de vari\u00e1veis num\u00e9ricas, categ\u00f3ricas e bin\u00e1rias obtidas por raspagem. Trata-se de um dataset pequeno, com algumas vari\u00e1veis com outliers e certo n\u00edvel de ru\u00eddo, o que impactou diretamente o desempenho e estabilidade de alguns modelos.</p> <p>Ap\u00f3s o pr\u00e9-processamento, incluindo padroniza\u00e7\u00e3o, codifica\u00e7\u00e3o categ\u00f3rica e remo\u00e7\u00e3o de registros inconsistentes, quatro abordagens principais foram testadas: Regress\u00e3o Linear M\u00faltipla, Random Forest, KNN e SVM (kernel linear).</p> <ul> <li> <p>Random Forest: apresentou bom desempenho inicial, mas sofreu com overfitting severo e grande oscila\u00e7\u00e3o entre folds. Com poucos dados e um alvo de baixa variabilidade, as \u00e1rvores n\u00e3o conseguiram generalizar bem.</p> </li> <li> <p>KNN: apesar de ter obtido resultados s\u00f3lidos, mostrou instabilidade na valida\u00e7\u00e3o cruzada e maior sensibilidade ao ru\u00eddo. Comportamento esperado para m\u00e9todos baseados em vizinhan\u00e7a.</p> </li> <li> <p>Regress\u00e3o Linear M\u00faltipla: apresentou bom desempenho geral, com alto R\u00b2 de 92% e sem evid\u00eancia de overfitting. Contudo, sofre com a instabilidade dos dados da base, como \u00e9 poss\u00edvel observar pela varia\u00e7\u00e3o do R\u00b2 entre os folds.</p> </li> <li> <p>SVM Linear: entregou o melhor equil\u00edbrio geral. Apresentou alto R\u00b2 de 92,16% (0,16% maior do que da regress\u00e3o), baixo RMSE, \u00f3tima generaliza\u00e7\u00e3o e quase nenhuma evid\u00eancia de overfitting, sendo robusto mesmo com poucas observa\u00e7\u00f5es. Apesar disso, tamb\u00e9m sofre com a instabilidade dos dados da base, mesmo que bem menos do que os outros modelos.</p> </li> </ul> <p>Portanto, o modelo escolhido como solu\u00e7\u00e3o final foi o SVM Linear, pois forneceu o melhor desempenho consistente, maior estabilidade e se mostrou o m\u00e9todo mais adequado para a estrutura e tamanho reduzido do dataset. Apesar disso, a Regress\u00e3o Linear M\u00faltipla possui desempenho quase id\u00eantico, ent\u00e3o, tamb\u00e9m pode ser utilizada nesse caso.</p>"}]}